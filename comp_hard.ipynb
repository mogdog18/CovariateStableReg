{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant LinearRegression. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant Lasso. This may fail, cause incorrect answers, or produce other errors.\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mModule model_selection has been ported to Julia - try `import ScikitLearn: CrossValidation` instead\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ ScikitLearn.Skcore ~/.julia/packages/ScikitLearn/sqLdT/src/Skcore.jl:259\u001b[39m\n",
      "WARNING: redefinition of constant train_test_split. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant StandardScaler. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <class 'sklearn.preprocessing._data.StandardScaler'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV, DataFrames, Statistics, Random, Plots, JuMP, Gurobi\n",
    "using ScikitLearn\n",
    "@sk_import linear_model: LinearRegression\n",
    "@sk_import linear_model: Lasso\n",
    "@sk_import model_selection: train_test_split\n",
    "@sk_import preprocessing: StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opt_split (generic function with 2 methods)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function opt_split(X, y, n, p, k, lambda, weight = nothing)\n",
    "    # add column of ones\n",
    "    X = hcat(ones(Int, size(X, 1)), X)\n",
    "    p = p + 1\n",
    "\n",
    "    model = Model(Gurobi.Optimizer)\n",
    "    set_optimizer_attribute(model, \"OutputFlag\", 0)\n",
    "\n",
    "    @variable(model, theta)\n",
    "    @variable(model, u[1:n] >= 0)\n",
    "    @variable(model, beta[1:p])\n",
    "    @variable(model, w[1:p])\n",
    "\n",
    "    @objective(model, Min, k * theta + sum(u) + lambda * sum(w))\n",
    "\n",
    "    for i in 1:p\n",
    "        @constraint(model, w[i] >= beta[i])\n",
    "        @constraint(model, w[i] >= -beta[i])\n",
    "    end \n",
    "\n",
    "    for i in 1:n\n",
    "        if weight == nothing\n",
    "            @constraint(model, theta + u[i] >= y[i] - sum(X[i, :].*beta))\n",
    "            @constraint(model, theta + u[i] >= -(y[i] - sum(X[i, :].*beta)))\n",
    "        else \n",
    "            @constraint(model, theta + u[i] >=  weight[i] * (y[i] - sum(X[i, :].*beta)))\n",
    "            @constraint(model, theta + u[i] >= - weight[i] * (y[i] - sum(X[i, :].*beta)))\n",
    "        end \n",
    "    end\n",
    "    \n",
    "    optimize!(model)\n",
    "\n",
    "    return value(theta), value.(u), value.(beta), value.(w)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split_train_val (generic function with 3 methods)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function split_train_val(X, y, beta_star, train_fraction = 0.8, weights = nothing)\n",
    "    # add column of ones\n",
    "    X = hcat(ones(Int, size(X, 1)), X)\n",
    "\n",
    "    residuals = y - X * beta_star\n",
    "\n",
    "    if weights == nothing\n",
    "        sorted_indices = sortperm(abs.(residuals), rev=true)\n",
    "    else \n",
    "        residuals_weights = [residuals[i] * weights[i] for i in 1:length(weights)]\n",
    "        sorted_indices = sortperm(abs.(residuals_weights), rev=true)\n",
    "    end\n",
    "\n",
    "    num_train_points = round(Int, train_fraction * length(sorted_indices))\n",
    "\n",
    "    train_indices = sorted_indices[1:num_train_points]\n",
    "\n",
    "    val_indices = setdiff(1:length(y), train_indices)\n",
    "\n",
    "    X_train = X[train_indices, 2:end]\n",
    "    y_train = y[train_indices, :]\n",
    "\n",
    "    X_val = X[val_indices, 2:end]\n",
    "    y_val = y[val_indices, :]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_evaluate_model (generic function with 1 method)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fit_evaluate_model(X_train, X_val, X_test, y_train, y_val, y_test, lambdas)\n",
    "    current_lambda = Inf\n",
    "    current_val_mse = Inf\n",
    "    current_test_mse = Inf\n",
    "    \n",
    "    for lambda in lambdas\n",
    "\n",
    "        model = Lasso(alpha=lambda, max_iter = 20000)\n",
    "        fit!(model, X_train, y_train)\n",
    "        \n",
    "        y_pred_val = predict(model, X_val)\n",
    "        val_mse_i = mse(y_val, y_pred_val)\n",
    "        \n",
    "        if current_val_mse >= val_mse_i\n",
    "            current_lambda = lambda\n",
    "            current_val_mse = val_mse_i\n",
    "            current_test_mse = mse(y_test, predict(model, X_test))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    println(\"best lambda: \", current_lambda)\n",
    "    println(\"val score: \", current_val_mse)\n",
    "    println(\"test score: \", current_test_mse)\n",
    "\n",
    "    return current_val_mse, current_test_mse\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mse (generic function with 1 method)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mse(y_true, y_pred)\n",
    "    mse = mean((y_true .- y_pred).^2)\n",
    "    return mse\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comp Hard dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = CSV.read(\"data/comp_hard/machine.data\", header = false, DataFrame)\n",
    "df_names = [\"Vendor_Name\", \"Model_Name\", \"MYCT\", \"MMIN\", \"MMAX\", \"CACH\", \"CHMIN\", \"CHMAX\", \"PRP\", \"ERP\"]\n",
    "rename!(df, Symbol.(df_names))\n",
    "\n",
    "feature_list = [\"MYCT\", \"MMIN\", \"MMAX\", \"CACH\", \"CHMIN\", \"CHMAX\", \"PRP\"]\n",
    "X = df[:, feature_list]\n",
    "y = df[!, \"ERP\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalize_data (generic function with 1 method)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function normalize_data(X_train, X_test)\n",
    "    # Calculate mean and standard deviation from training data\n",
    "    mean_vals = mean(X_train, dims=1)\n",
    "    std_vals = std(X_train, dims=1)\n",
    "\n",
    "    # Normalize training data\n",
    "    X_train_norm = (X_train .-mean_vals) ./ std_vals;\n",
    "    X_test_norm = (X_test .-mean_vals) ./ std_vals;\n",
    "\n",
    "    return X_train_norm, X_test_norm\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) =\n",
    "    IAI.split_data(:regression, X, y, train_proportion=0.9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_norm, test_X_norm = normalize_data(Matrix(train_X), Matrix(test_X));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get optimised split \n",
    "n = nrow(train_X)\n",
    "p = ncol(train_X)\n",
    "train_fraction = 0.7\n",
    "k = n * train_fraction\n",
    "lambda = 0.001;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-09-11\n"
     ]
    }
   ],
   "source": [
    "#get optimised split\n",
    "_, _, betas_star, _ = opt_split(train_X_norm, Array(train_y), n, p, k, lambda)\n",
    "X_train_opt, y_train_opt, X_val_opt, y_val_opt= split_train_val(train_X_norm, Array(train_y), betas_star);\n",
    "\n",
    "#get non optimised split \n",
    "(X_train_rand, y_train_rand), (X_val_rand, y_val_rand) =\n",
    "    IAI.split_data(:regression, train_X_norm, train_y, train_proportion=train_fraction);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best lambda: 0.1\n",
      "val score: 129.74951750953483\n",
      "test score: 1255.246060821048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(129.74951750953483, 1255.246060821048)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas = [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "fit_evaluate_model(X_train_opt, X_val_opt, Matrix(test_X_norm), y_train_opt, y_val_opt, Array(test_y), lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best lambda: 0.1\n",
      "val score: 1268.7514238010428\n",
      "test score: 1522.9794563294136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1268.7514238010428, 1522.9794563294136)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_evaluate_model(Matrix(X_train_rand), Matrix(X_val_rand), Matrix(test_X_norm), Array(y_train_rand), y_val_rand, Array(test_y), lambdas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (IAI) 4 1.9.3",
   "language": "julia",
   "name": "julia-_iai_-4-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "683a8f5228cdb2dfe20440e7c79750b7ef6077ddd22e2c437eb1bcaa2db9b8fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
